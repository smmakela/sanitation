Before I started grad school, I read Andrew's blog almost every day at work, and it was hugely influential on how I think about statistics, causal inference, and modeling. In particular, I was struck by his arguments that, in the social sciences, there are (almost) no true zeros. As an undergrad with a math background working in global health at the time and having no formal statistics (or public health) training, this argument made intuitive sense to me: human beings are complicated and interact in myriad unpredictable ways, so why would we believe that the causal effect of program X on outcome Y is exactly zero? I suppose this is one of the reasons underlying his fundamental disagreement with Pearl on how we should go about investigating causality. Pearl's framework begins with asserting a causal graph where missing edges between a variable and the outcome imply a belief that the direct causal effect of that variable on the outcome is exactly zero. Gelman, on the other hand, is skeptical of the goal of trying to learn the structure of the causal graph and the notion that we would a priori believe that some effects are exactly zero.
Perhaps it is my own view of human nature and social science that leads me to agree with Gelman when he says "I certainly don’t see any simple relationships between income, religious attendance, party identification, and voting—and I don’t see how a search for such a pattern will advance our understanding, at least given current techniques"; to me this idea applies to the relationships between, for example, education, sex, health behaviors, and health outcomes, for example, or any other number of variables that we see in social science data.
I think this idea ties in very neatly with Bayesian inference in general. Why would we content ourselves with testing the null hypothesis that some particular causal effect is exactly zero against an alternative that it is nonzero, when instead we could develop a Bayesian model that allows us to incorporate our substantive knowledge and gives us a *distribution* of causal effects that are consistent with the data and our knowledge? If I'm evaluating an intervention to increase vaccination rates or trying to understand the relationship between women's empowerment and child health, I'd much prefer a posterior distribution of the corresponding quantities of interest to a single t-statistic and p-value.